{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install librosa","execution_count":1,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (0.8.0)\nRequirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.18.5)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.2.0)\nRequirement already satisfied: soundfile>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.10.3.post1)\nRequirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (2.1.8)\nRequirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.48.0)\nRequirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.14.1)\nRequirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (4.4.2)\nRequirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (1.4.1)\nRequirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from librosa) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (20.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (2.23.0)\nRequirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from pooch>=1.0->librosa) (1.4.3)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa) (1.14.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (46.1.3.post20200325)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa) (0.31.0)\nRequirement already satisfied: six>=1.3 in /opt/conda/lib/python3.7/site-packages (from resampy>=0.2.2->librosa) (1.14.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2020.6.20)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (2.9)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->pooch>=1.0->librosa) (1.24.3)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\n\ns, sr  = librosa.load(\"../input/denoise-data/train_clean_male.wav\" , sr=None)\nS = librosa.stft( s , n_fft=1024 , hop_length=512)\nsn , sr = librosa.load(\"../input/denoise-data/train_dirty_male.wav\" , sr=None)\nX = librosa.stft(sn , n_fft=1024 , hop_length=512)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Input Clear voice data shape : \", S.shape)\nprint(\"Input Noise voice data shape : \", X.shape)","execution_count":3,"outputs":[{"output_type":"stream","text":"Input Clear voice data shape :  (513, 2459)\nInput Noise voice data shape :  (513, 2459)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nS_abs = np.abs(S)\nX_abs = np.abs(X)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"S_in = np.swapaxes(S_abs , 0 , 1)\nX_in = np.swapaxes(X_abs , 0 , 1)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Libraries\nfrom __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.autograd import Variable","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    #This defines the structure of the NN.\n    def __init__(self , activation='relu'):\n        super(Net, self).__init__()\n        self.wav_size = 513\n        self.fc1 = nn.Linear(self.wav_size, 1024)      \n        self.fc2 = nn.Linear(1024, 1024 )               \n        self.fc3 = nn.Linear(1024,1024 )                    \n        self.fc4 = nn.Linear(1024,1024 )                    \n        self.fc5 = nn.Linear(1024,1024 )                    \n        self.fc6 = nn.Linear(1024,1024 ) \n        self.fc7 = nn.Linear(1024,1024 ) \n        self.fc8 = nn.Linear(1024,1024 ) \n        self.fc9 = nn.Linear(1024,1024 ) \n        self.fc10 = nn.Linear(1024,1024 ) \n        self.out_layer = nn.Linear(1024,self.wav_size)                # output layer\n        #select the activation function\n        if(activation=='relu'):\n            self.activation_fn = nn.ReLU()\n        if(activation=='logistic_sigmoid'):\n            self.activation_fn = nn.LogSigmoid()\n\n    def forward(self, x):\n        #flatten the input vector\n        x = x.view(-1, self.wav_size)\n        #Linear Layer 1 /Activation\n        x = self.activation_fn( self.fc1(x) ) \n        #Linear Layer 2 /Activation\n        x = self.activation_fn( self.fc2(x) ) \n        #Linear Layer 3 /Activation\n        #x = self.activation_fn( self.fc3(x) ) \n        #Linear Layer 4 /Activation\n        #x = self.activation_fn( self.fc4(x) ) \n        #Linear Layer 5 /Activation\n        #x = self.activation_fn( self.fc5(x) ) \n        #Linear Layer 5 /Activation\n        out = self.activation_fn(self.out_layer(x))\n        #Softmax gets probabilities. \n        return out\n\n\n#model weight initialization function \ndef init_weights_normal(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.normal_(m.weight , mean=0 , std=0.01)\n        m.bias.data.fill_(0)\n\ndef init_weights_xavier(m):\n    if type(m) == nn.Linear:      \n        torch.nn.init.xavier_normal_(m.weight , gain=0.8)\n        m.bias.data.fill_(0)\ndef init_weights_kaiman(m):\n    if type(m) == nn.Linear:\n        torch.nn.init.kaiming_normal_(m.weight)\n        m.bias.data.fill_(0)","execution_count":115,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset , DataLoader\n\nclass Wav_DataGenerator(Dataset):\n    def __init__(self , noise_wav , clean_wav , seed):\n        super(Wav_DataGenerator , self).__init__()\n        self.noise_wav = noise_wav\n        self.clean_wav = clean_wav\n        self.seed = torch.manual_seed(seed)\n        \n    def __getitem__(self , index):\n        \n        data_x = self.noise_wav[index]\n        data_y = self.clean_wav[index]\n        \n        return data_x , data_y\n        \n    def __len__(self ):\n        return len(self.noise_wav)\n    ","execution_count":116,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = Wav_DataGenerator(X_in , S_in , 1264)\ntrain_dataloader = DataLoader(train_data , batch_size=32 , shuffle=True)","execution_count":117,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the model\ndevice=\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\nDenoise_Model = Net()\nDenoise_Model.apply(init_weights_normal)\nDenoise_Model.to(device)","execution_count":118,"outputs":[{"output_type":"execute_result","execution_count":118,"data":{"text/plain":"Net(\n  (fc1): Linear(in_features=513, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc6): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc8): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc9): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc10): Linear(in_features=1024, out_features=1024, bias=True)\n  (out_layer): Linear(in_features=1024, out_features=513, bias=True)\n  (activation_fn): ReLU()\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the model optimizer and loss\noptimizer = optim.Adam(Denoise_Model.parameters() , lr=0.001)\n#L2 loss function\ncriterion = nn.MSELoss()","execution_count":119,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#training the model\nepoch = 50\nmodel_train_loss = []\n\n\nfor i_epoch in range(epoch):\n    epoch_loss = 0\n    for batch_idx, (data, target) in enumerate(train_dataloader):\n\n        data, target = data.to(device) , target.to(device)\n        #Variables in Pytorch are differenciable. \n        data, target = Variable(data), Variable(target)\n        #This will zero out the gradients for this batch. \n        optimizer.zero_grad()\n        output = Denoise_Model(data)\n        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n        loss =criterion(output, target)\n        #dloss/dx for every Variable \n        loss.backward()\n        #to do a one-step update on our parameter.\n        optimizer.step()\n        epoch_loss += loss.detach().to('cpu').item()\n        #Print out the loss periodically. \n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                i_epoch, batch_idx * len(data), len(train_dataloader.dataset),\n                100. * batch_idx / len(train_dataloader), loss.detach().item()))","execution_count":120,"outputs":[{"output_type":"stream","text":"Train Epoch: 0 [0/2459 (0%)]\tLoss: 0.071983\nTrain Epoch: 1 [0/2459 (0%)]\tLoss: 0.039576\nTrain Epoch: 2 [0/2459 (0%)]\tLoss: 0.031114\nTrain Epoch: 3 [0/2459 (0%)]\tLoss: 0.006137\nTrain Epoch: 4 [0/2459 (0%)]\tLoss: 0.013450\nTrain Epoch: 5 [0/2459 (0%)]\tLoss: 0.019647\nTrain Epoch: 6 [0/2459 (0%)]\tLoss: 0.011625\nTrain Epoch: 7 [0/2459 (0%)]\tLoss: 0.018671\nTrain Epoch: 8 [0/2459 (0%)]\tLoss: 0.016904\nTrain Epoch: 9 [0/2459 (0%)]\tLoss: 0.009538\nTrain Epoch: 10 [0/2459 (0%)]\tLoss: 0.010279\nTrain Epoch: 11 [0/2459 (0%)]\tLoss: 0.008527\nTrain Epoch: 12 [0/2459 (0%)]\tLoss: 0.012256\nTrain Epoch: 13 [0/2459 (0%)]\tLoss: 0.016064\nTrain Epoch: 14 [0/2459 (0%)]\tLoss: 0.006461\nTrain Epoch: 15 [0/2459 (0%)]\tLoss: 0.027334\nTrain Epoch: 16 [0/2459 (0%)]\tLoss: 0.011878\nTrain Epoch: 17 [0/2459 (0%)]\tLoss: 0.008196\nTrain Epoch: 18 [0/2459 (0%)]\tLoss: 0.007275\nTrain Epoch: 19 [0/2459 (0%)]\tLoss: 0.004643\nTrain Epoch: 20 [0/2459 (0%)]\tLoss: 0.007534\nTrain Epoch: 21 [0/2459 (0%)]\tLoss: 0.005492\nTrain Epoch: 22 [0/2459 (0%)]\tLoss: 0.006083\nTrain Epoch: 23 [0/2459 (0%)]\tLoss: 0.004858\nTrain Epoch: 24 [0/2459 (0%)]\tLoss: 0.003119\nTrain Epoch: 25 [0/2459 (0%)]\tLoss: 0.007211\nTrain Epoch: 26 [0/2459 (0%)]\tLoss: 0.010598\nTrain Epoch: 27 [0/2459 (0%)]\tLoss: 0.003309\nTrain Epoch: 28 [0/2459 (0%)]\tLoss: 0.005695\nTrain Epoch: 29 [0/2459 (0%)]\tLoss: 0.003656\nTrain Epoch: 30 [0/2459 (0%)]\tLoss: 0.006933\nTrain Epoch: 31 [0/2459 (0%)]\tLoss: 0.003567\nTrain Epoch: 32 [0/2459 (0%)]\tLoss: 0.004352\nTrain Epoch: 33 [0/2459 (0%)]\tLoss: 0.003197\nTrain Epoch: 34 [0/2459 (0%)]\tLoss: 0.003786\nTrain Epoch: 35 [0/2459 (0%)]\tLoss: 0.009035\nTrain Epoch: 36 [0/2459 (0%)]\tLoss: 0.002065\nTrain Epoch: 37 [0/2459 (0%)]\tLoss: 0.002945\nTrain Epoch: 38 [0/2459 (0%)]\tLoss: 0.010033\nTrain Epoch: 39 [0/2459 (0%)]\tLoss: 0.003674\nTrain Epoch: 40 [0/2459 (0%)]\tLoss: 0.003129\nTrain Epoch: 41 [0/2459 (0%)]\tLoss: 0.009920\nTrain Epoch: 42 [0/2459 (0%)]\tLoss: 0.002208\nTrain Epoch: 43 [0/2459 (0%)]\tLoss: 0.003229\nTrain Epoch: 44 [0/2459 (0%)]\tLoss: 0.002484\nTrain Epoch: 45 [0/2459 (0%)]\tLoss: 0.003748\nTrain Epoch: 46 [0/2459 (0%)]\tLoss: 0.003143\nTrain Epoch: 47 [0/2459 (0%)]\tLoss: 0.013967\nTrain Epoch: 48 [0/2459 (0%)]\tLoss: 0.003060\nTrain Epoch: 49 [0/2459 (0%)]\tLoss: 0.006108\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tn , sr = librosa.load(\"../input/denoise-data/test_x_01.wav\" , sr=None)\nX = librosa.stft(tn , n_fft=1024 , hop_length=512)","execution_count":121,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_abs = np.abs(X)\nT_in = np.swapaxes(T_abs , 0 , 1)","execution_count":122,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_in_tensor = torch.tensor(T_in , dtype=torch.float32)","execution_count":123,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inference the model\nT_out_tensor = Denoise_Model(T_in_tensor.to(device))","execution_count":124,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_out = T_out_tensor.detach().to(\"cpu\").numpy()\nT_out = np.swapaxes(T_out , 0 , 1)","execution_count":125,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_phase = X / T_abs","execution_count":126,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_phase.shape","execution_count":127,"outputs":[{"output_type":"execute_result","execution_count":127,"data":{"text/plain":"(513, 142)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"T_out.shape","execution_count":128,"outputs":[{"output_type":"execute_result","execution_count":128,"data":{"text/plain":"(513, 142)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#do Hadamard product\nS_hat = np.multiply(T_phase,T_out)","execution_count":129,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import soundfile as sf\n\niStftMat = librosa.istft(S_hat, hop_length=512)\n\nsf.write(\"testOut.wav\", iStftMat , sr)","execution_count":130,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}